{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472153ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import math\n",
    "import random \n",
    "import os \n",
    "import cv2\n",
    "import timm\n",
    "\n",
    "from tqdm import tqdm \n",
    "import h5py\n",
    "\n",
    "import albumentations as A \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset \n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import gc\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75acd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    DATA_DIR = '/mnt/hdd1/wearly/compatibility_rec/data/images/'\n",
    "    TRAIN_CSV = '/mnt/hdd1/wearly/deep_rec/separ_train.csv'\n",
    "    TEST_CSV = '/mnt/hdd1/wearly/deep_rec/separ_test.csv'\n",
    "    SEED = 123\n",
    "\n",
    "    IMG_SIZE = 224\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    BATCH_SIZE = 128\n",
    "    N_FOLDS = 10\n",
    "    FC_DIM = 512\n",
    "    \n",
    "    NUM_WORKERS = 4\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')#'cuda:0'\n",
    "     \n",
    "    CLASSES = 5062\n",
    "    SCALE = 30 \n",
    "    MARGIN = 0.5\n",
    "\n",
    "    MODEL_NAME = 'tf_efficientnet_b3'\n",
    "    MODEL_PATH = './separ_tf_efficientnet_b3_60_Weights/tf_efficientnet_b3_16EpochStep_adam.pt'\n",
    "    TYP = \"test\"\n",
    "    \n",
    "\n",
    "def seed_setting(seed=Config.SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0547be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://data-newbie.tistory.com/472\n",
    "# 데이터 크기 확인 함수\n",
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)\n",
    "\n",
    "## 타입별 평균 크기 확인 함수\n",
    "def type_memory(data) :\n",
    "    for dtype in ['float','int','object']:\n",
    "        selected_dtype = data.select_dtypes(include=[dtype])\n",
    "        mean_usage_b = selected_dtype.memory_usage(deep=True).mean()\n",
    "        mean_usage_mb = mean_usage_b / 1024 ** 2\n",
    "        print(\"Average memory usage for {} columns: {:03.2f} MB\".format(dtype,mean_usage_mb))\n",
    "\n",
    "## 이산형 데이터 사이즈 축소 함소\n",
    "def int_memory_reduce(data) :\n",
    "    data_int = data.select_dtypes(include=['int'])\n",
    "    converted_int = data_int.apply(pd.to_numeric,downcast='unsigned')\n",
    "    print(f\"Before : {mem_usage(data_int)} -> After : {mem_usage(converted_int)}\")\n",
    "    data[converted_int.columns] = converted_int\n",
    "    return data\n",
    "\n",
    "## 연속형 데이터 사이즈 축소 함소\n",
    "def float_memory_reduce(data) :\n",
    "    data_float = data.select_dtypes(include=['float'])\n",
    "    converted_float = data_float.apply(pd.to_numeric,downcast='float')\n",
    "    print(f\"Before : {mem_usage(data_float)} -> After : {mem_usage(converted_float)}\")\n",
    "    data[converted_float.columns] = converted_float\n",
    "    return data\n",
    "\n",
    "## 문자형 데이터 사이즈 축소 함소\n",
    "def object_memory_reduce(data) :\n",
    "    gl_obj = data.select_dtypes(include=['object']).copy()\n",
    "    converted_obj = pd.DataFrame()\n",
    "    for col in gl_obj.columns:\n",
    "        num_unique_values = len(gl_obj[col].unique())\n",
    "        num_total_values = len(gl_obj[col])\n",
    "        if num_unique_values / num_total_values < 0.5:\n",
    "            converted_obj.loc[:,col] = gl_obj[col].astype('category')\n",
    "        else:\n",
    "            converted_obj.loc[:,col] = gl_obj[col]\n",
    "    print(f\"Before : {mem_usage(gl_obj)} -> After : {mem_usage(converted_obj)}\")\n",
    "    data[converted_obj.columns] = converted_obj\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "850a92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: frozenset(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: frozenset(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in tqdm(zip(y_true, y_pred))])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1, intersection\n",
    "\n",
    "def f1score_eval(df):\n",
    "    df['f1'], intersection = f1_score(df['label_group'], df['pred_matches'])\n",
    "    score = df['f1'].mean()\n",
    "    print(f'Our f1 score is {score}')\n",
    "    return score, intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b13a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_intersections(df):\n",
    "    y_true = df['label_group']\n",
    "    y_pred = df['pred_matches']\n",
    "    y_true = y_true.apply(lambda x: frozenset(x.split()))\n",
    "    #y_true = [frozenset(y_true[i].split()) for i in tqdm(range(leny_true))]\n",
    "    y_pred = y_pred.apply(lambda x: frozenset(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in tqdm(zip(y_true, y_pred))])\n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40dff3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/tanulsingh077/metric-learning-image-tfidf-inference\n",
    "def get_neighbors(df, embeddings, KNN = 30):\n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    predictions = []\n",
    "    for k in tqdm(range(embeddings.shape[0])):\n",
    "        idx = np.where(distances[k,] < 2.7)[0]\n",
    "        ids = indices[k,idx]\n",
    "        posting_ids = df['image_name'].iloc[ids].values\n",
    "        predictions.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return df, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63c47df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Embedding Loading Successful ----------\n",
      "---------- Annoy Model Loading Successful ----------\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('../embeddings/all_emb.h5','r')\n",
    "print(\"---------- Embedding Loading Successful ----------\")\n",
    "image_embeddings = h5f['all_data'][:]\n",
    "\n",
    "# annoy indexing\n",
    "vector_size = Config.FC_DIM\n",
    "load_index = AnnoyIndex(vector_size, 'dot')\n",
    "load_index.load('../embeddings/test.annoy')\n",
    "print(\"---------- Annoy Model Loading Successful ----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4856332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(559922, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label_group</th>\n",
       "      <th>pred_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/manish_546453_best.jpg</td>\n",
       "      <td>train/manish_546453_best.jpg train/modern_7091...</td>\n",
       "      <td>train/street_963468_jacket.jpg train/street_13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/modern_709120_best.jpg</td>\n",
       "      <td>train/manish_546453_best.jpg train/modern_7091...</td>\n",
       "      <td>train/sophisticated_1138022_best.jpg val/sophi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/classic_746922_best.jpg</td>\n",
       "      <td>train/manish_546453_best.jpg train/modern_7091...</td>\n",
       "      <td>train/sophisticated_1138022_best.jpg train/mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image_name  \\\n",
       "0   train/manish_546453_best.jpg   \n",
       "1   train/modern_709120_best.jpg   \n",
       "2  train/classic_746922_best.jpg   \n",
       "\n",
       "                                         label_group  \\\n",
       "0  train/manish_546453_best.jpg train/modern_7091...   \n",
       "1  train/manish_546453_best.jpg train/modern_7091...   \n",
       "2  train/manish_546453_best.jpg train/modern_7091...   \n",
       "\n",
       "                                        pred_matches  \n",
       "0  train/street_963468_jacket.jpg train/street_13...  \n",
       "1  train/sophisticated_1138022_best.jpg val/sophi...  \n",
       "2  train/sophisticated_1138022_best.jpg train/mod...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../embeddings/all_dt_eval.pkl\")\n",
    "df.pred_matches = df.pred_matches.astype(\"category\")\n",
    "df.label_group = df.label_group.astype(\"category\")\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbf8d38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55993, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/modern_1220850_best.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/street_61802_best.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val/country_881566_best.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image_name\n",
       "0  train/modern_1220850_best.jpg\n",
       "1    train/street_61802_best.jpg\n",
       "2    val/country_881566_best.jpg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = pd.read_csv(\"../separ_test.csv\", index_col=0)\n",
    "te = te[[\"image_name\"]]\n",
    "print(te.shape)\n",
    "te.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98703aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(te, df, on=\"image_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "959da8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_ls = [frozenset(df.label_group[i].split()) for i in tqdm(range(len(df.label_group)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbbf53c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m intersection \u001b[38;5;241m=\u001b[39m \u001b[43mgain_intersections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mgain_intersections\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m y_true \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_group\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_matches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43my_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfrozenset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#y_true = [frozenset(y_true[i].split()) for i in tqdm(range(leny_true))]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mfrozenset\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit()))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:4138\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4137\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 4138\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], Series):\n\u001b[1;32m   4141\u001b[0m     \u001b[38;5;66;03m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m     \u001b[38;5;66;03m# so extension arrays can be used\u001b[39;00m\n\u001b[1;32m   4143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2467\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mgain_intersections.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m y_true \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_group\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_matches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mfrozenset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#y_true = [frozenset(y_true[i].split()) for i in tqdm(range(leny_true))]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mfrozenset\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit()))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "intersection = gain_intersections(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, intersection = f1score_eval(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"intersection\"] = intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"precision\"] = df[\"intersection\"] / 20\n",
    "df[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b2e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf, predictions = get_neighbors(df, image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab545b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[\"pred_matches\"] = predictions\n",
    "ddf['pred_matches'] = [' '.join(x) for x in tqdm(ddf['pred_matches'].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5905bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, intersection = f1score_eval(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[\"intersection\"] = intersection\n",
    "ddf[\"precision\"] = ddf[\"intersection\"] / 20\n",
    "ddf[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73df613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
