{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "formed-cooling",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os \n",
    "import cv2 \n",
    "import timm \n",
    "\n",
    "import albumentations \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "from torch import nn \n",
    "from torch.optim import Adam\n",
    "\n",
    "import math\n",
    "import neptune\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR, OneCycleLR, _LRScheduler, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-tower",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    DATA_DIR = '/mnt/hdd1/wearly/compatibility_rec/data/images/'\n",
    "    TRAIN_CSV = '/mnt/hdd1/wearly/deep_rec/separ_train.csv'\n",
    "    SEED = 225\n",
    "    SAVE_NAME = 'separ'\n",
    "\n",
    "    IMG_SIZE = 512#224\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    EPOCHS = 50 #15  # Try 15 epochs\n",
    "    BATCH_SIZE = 16#32#64\n",
    "    N_FOLDS = 10\n",
    "    \n",
    "    NUM_WORKERS = 4\n",
    "    DEVICE = 'cuda:1'#torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    #HEIGHT=512 #for augmentation\n",
    "    #WIDTH=512\n",
    "    \n",
    "    CLASSES = 352#1272\n",
    "    SCALE = 30 \n",
    "    MARGIN = 0.5\n",
    "\n",
    "    MODEL_NAME =  'tf_efficientnet_b4'\n",
    "    FC_DIM = 512\n",
    "    \n",
    "    #LR\n",
    "    LR_START = 1e-5\n",
    "    \n",
    "    weight_decay = 0.0\n",
    "    optimizer_name = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_setting():\n",
    "    seed = Config.SEED\n",
    "    torch.cuda.set_device(Config.DEVICE)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_df(df):\n",
    "    \n",
    "    train_df = df.copy()\n",
    "    \n",
    "    train_df['fold'] = -1\n",
    "    \n",
    "    n_folds = Config.N_FOLDS\n",
    "    \n",
    "    strat_kfold = StratifiedKFold(n_splits=n_folds, random_state = Config.SEED, shuffle=True)\n",
    "\n",
    "    for i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['label_group'])):\n",
    "        train_df.iloc[train_index,-1] = i\n",
    "\n",
    "    train_df['fold'] = train_df['fold'].astype('int')\n",
    "    \n",
    "    if n_folds == 10:\n",
    "        train = train_df[train_df.fold != 0].reset_index(drop=True)\n",
    "        valid = train_df[train_df.fold == 0].reset_index(drop=True)\n",
    "        \n",
    "        return train,valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-device",
   "metadata": {},
   "source": [
    "### Neptune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neptune.init(project_qualified_name = \"younghoon/Deep-rec\",\n",
    "#               api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmMTAxYTc0NS1kMWFlLTQwNjEtYWQ2OS04ODM3ZGI1YTA2ZjUifQ==\",\n",
    "#               )\n",
    "# #pass parameters to create experiment\n",
    "# neptune.create_experiment(params=  None , name= Config.MODEL_NAME, description = f'train {Config.EPOCHS}'\n",
    "#                           , tags=['efficientnet_b4','30epochs','one-cycle-lr'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-dispute",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KfashionDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,df,transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = Config.DATA_DIR\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.root_dir, row.image_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = row.label_group\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return {\n",
    "            'image' : image,\n",
    "            'label' : torch.tensor(label).long()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-examination",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(Config.IMG_SIZE, Config.IMG_SIZE, always_apply=True),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=120, p=0.8),\n",
    "            albumentations.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n",
    "            albumentations.Normalize(mean = Config.MEAN, std = Config.STD),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transforms():\n",
    "\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(Config.IMG_SIZE, Config.IMG_SIZE,always_apply=True),\n",
    "            albumentations.Normalize(),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-singapore",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-blocking",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-mitchell",
   "metadata": {},
   "source": [
    "### Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credit : https://github.com/tyunist/memory_efficient_mish_swish/blob/master/mish.py\n",
    "\n",
    "''' I just wanted to understand and implement custom backward activation in PyTorch so I choose this.\n",
    "    You can also simply use this function below too.\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mish, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input * (torch.tanh(F.softplus(input)))\n",
    "'''\n",
    "\n",
    "class Mish_func(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.tanh(F.softplus(i))\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_tensors[0]\n",
    "        v = 1. + i.exp()\n",
    "        h = v.log() \n",
    "        grad_gh = 1./h.cosh().pow_(2) \n",
    "\n",
    "        # Note that grad_hv * grad_vx = sigmoid(x)\n",
    "        #grad_hv = 1./v  \n",
    "        #grad_vx = i.exp()\n",
    "        \n",
    "        grad_hx = i.sigmoid()\n",
    "\n",
    "        grad_gx = grad_gh *  grad_hx #grad_hv * grad_vx \n",
    "        \n",
    "        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n",
    "        \n",
    "        return grad_output * grad_f \n",
    "\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        print(\"Mish initialized\")\n",
    "        pass\n",
    "    def forward(self, input_tensor):\n",
    "        return Mish_func.apply(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_activations(model, existing_layer, new_layer):\n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            model._modules[name] = replace_activations(module, existing_layer, new_layer)\n",
    "\n",
    "        if type(module) == existing_layer:\n",
    "            layer_old = module\n",
    "            layer_new = new_layer\n",
    "            model._modules[name] = layer_new\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-young",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device=Config.DEVICE)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "        return output, nn.CrossEntropyLoss()(output,label)\n",
    "\n",
    "class KfashionModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = Config.CLASSES,\n",
    "        model_name = Config.MODEL_NAME,\n",
    "        fc_dim = Config.FC_DIM,\n",
    "        margin = Config.MARGIN,\n",
    "        scale = Config.SCALE,\n",
    "        use_fc = True,\n",
    "        pretrained = True):\n",
    "\n",
    "\n",
    "        super(KfashionModel,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif 'efficientnet' in model_name:\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif 'nfnet' in model_name:\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=0.0)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProduct(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        logits = self.final(feature,label)\n",
    "        return logits\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-regard",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, data_loader, optimizer, scheduler, i):\n",
    "    model.train()\n",
    "    fin_loss = 0.0\n",
    "    tk = tqdm(data_loader, desc = \"Epoch\" + \" [TRAIN] \" + str(i+1))\n",
    "\n",
    "    for t,data in enumerate(tk):\n",
    "        for k,v in data.items():\n",
    "            data[k] = v.to(Config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        _, loss = model(**data)\n",
    "        loss.mean().backward()\n",
    "        optimizer.step() \n",
    "        fin_loss += loss.mean().item() \n",
    "\n",
    "        tk.set_postfix({'loss' : '%.6f' %float(fin_loss/(t+1)), 'LR' : optimizer.param_groups[0]['lr']})\n",
    "        \n",
    "        #neptune.log_metric('loss_tr',float(fin_loss/(t+1)))\n",
    "        #neptune.log_metric('train_lr',optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "    #scheduler.step()\n",
    "\n",
    "    return fin_loss / len(data_loader)\n",
    "\n",
    "def eval_fn(model, data_loader, i):\n",
    "    model.eval()\n",
    "    fin_loss = 0.0\n",
    "    tk = tqdm(data_loader, desc = \"Epoch\" + \" [VALID] \" + str(i+1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t,data in enumerate(tk):\n",
    "            for k,v in data.items():\n",
    "                data[k] = v.to(Config.DEVICE)\n",
    "            _, loss = model(**data)\n",
    "            fin_loss += loss.mean().item() \n",
    "\n",
    "            tk.set_postfix({'loss' : '%.6f' %float(fin_loss/(t+1))})\n",
    "            \n",
    "            #neptune.log_metric('loss_valid', float(fin_loss/(t+1)))\n",
    "            \n",
    "        return fin_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    \n",
    "    seed_setting()\n",
    "    \n",
    "    df = pd.read_csv(Config.TRAIN_CSV, index_col=0)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    train,valid = stratify_df(df)\n",
    "    print(f\"train shape : {train.shape}\")\n",
    "    print(f\"validation shape : {valid.shape}\")\n",
    "    \n",
    "    print(train.label_group.nunique())\n",
    "    print(valid.label_group.nunique())\n",
    "    \n",
    "    #train\n",
    "    train_dataset = KfashionDataset(train, transform = get_train_transforms())    \n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = Config.BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        num_workers = Config.NUM_WORKERS,\n",
    "        shuffle = True,\n",
    "        drop_last = True\n",
    "    )\n",
    "    \n",
    "    #valid 추가\n",
    "    valid_dataset = KfashionDataset(valid, transform = get_valid_transforms())\n",
    "    validloader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size = Config.BATCH_SIZE,\n",
    "        num_workers = Config.NUM_WORKERS,\n",
    "        shuffle = False,\n",
    "        pin_memory = True,\n",
    "        drop_last = False\n",
    "        )\n",
    "    \n",
    "    \n",
    "    model = KfashionModel()\n",
    "    #model = nn.DataParallel(model)\n",
    "    model.to(Config.DEVICE)\n",
    "    \n",
    "    #existing_layer = torch.nn.SiLU\n",
    "    #new_layer = Mish()\n",
    "    #model = replace_activations(model, existing_layer, new_layer) # in eca_nfnet_l0 SiLU() is used, but it will be replace by Mish()\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr = Config.LR_START)\n",
    "    #scheduler = OneCycleLR(optimizer, max_lr = 2e-3, steps_per_epoch = len(trainloader),epochs=Config.EPOCHS)\n",
    "    \n",
    "    save_dir = f'./{Config.SAVE_NAME}_{Config.MODEL_NAME}_{Config.EPOCHS}_{Config.optimizer_name}_Weights'\n",
    "    \n",
    "    if os.path.exists(save_dir) == False :\n",
    "        print('Making Weights Folder')\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    \n",
    "    for i in range(Config.EPOCHS):\n",
    "        avg_loss_train = train_fn(model, trainloader, optimizer, None, i)\n",
    "        avg_loss_valid = eval_fn(model, validloader,i)\n",
    "        torch.save(model.state_dict(),f'{save_dir}/best_{i}EpochStep.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-brazilian",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-suspension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c65083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
